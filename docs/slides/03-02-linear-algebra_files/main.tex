\documentclass[times,t]{beamer}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{lmodern} 
\input{sym.tex}
\setbeamertemplate{navigation symbols}{}

\title{ECE 417/598: Null space, Singular Value Decompsition }
\author{Vikas Dhiman.  }
\date{March 2, 2022}
\begin{document}
\begin{frame}
  \titlepage
  \end{frame}

  \begin{frame}{Homogeneous representation of lines}
    \[ \bbP^2 = \bbR^3 - \{  (0, 0, 0)^\top \}   \]
    \[ ax + by + 1.c = 0\]
    \[ \bfl = \begin{bmatrix}
        a \\ b \\ c
        \end{bmatrix} \]
      \[ \bfx = \begin{bmatrix}
          x \\ y \\ 1
        \end{bmatrix} \]
      The point $\bfx \in \bbP^2$ lies on a line $\bfl$ if and only if
      \[ \bfl^\top \bfx = 0 \]
    \end{frame}

\begin{frame}{Points are rays and  lines are  planes}
  \includegraphics[width=\linewidth]{media/projective-plane-points-are-rays-and-lines-are-planes.png}
\end{frame}

\begin{frame}{Intersection of lines}
  Two line $\bfl_1$ and $\bfl_2$ intersect at $\bfx\in \bbP^2$
  \[ \bfx = \bfl_1 \times \bfl_2 \]
\end{frame}

\begin{frame}{Line joining  points}
  Two point $\bfx_1$ and $\bfx_2$ form a $\bfl \in \bbP^2$
  \[ \bfl = \bfx_1 \times \bfx_2 \]
\end{frame}

\newcommand{\ubfu}{\underline{\bfu}}
\begin{frame}
  \includegraphics[width=\linewidth]{media/lane-from-points.pdf}
  \begin{align*}
    \ubfu_1 &= [100, 98, 1]^\top\\
    \ubfu_2 &= [105, 95, 1]^\top\\
    \ubfu_3 &= [107, 90, 1]^\top\\
    \ubfu_4 &= [110, 85, 1]^\top
    \end{align*}
    Find  the line $\bfl$ such that it is the ``closest line'' passing through
    $\bfu_1, \dots, \bfu_4$.
\end{frame}

\begin{frame}
  \[
  U = \begin{bmatrix}\bfu_1^\top  \\
    \bfu_2^\top \\
    \bfu_3^\top \\
    \bfu_4^\top
  \end{bmatrix}
  \]
  We want to solve for $\bfl$ such that
  \[
    U \bfl = 0
  \]
\end{frame}


\begin{frame}

  The column space (also called the  range) of matrix $A \in \bbR^{m \times n}$, denoted by $\calR(A)$ is defined
  as the set of all vectors $\bfb \in \bbR^m$ that can be generated by $\bfb = A\bfx$
  where $\bfx \in \bbR^n$, that is,
  % 
  \begin{align}
    \calR(A) = \{ \bfb \mid \bfb = A\bfx\,\text{ for all } \bfx \in \bbR^n\}.
  \end{align}
  % 

  The nullspace of $A \in \bbR^{m \times n}$ is defined as the set of all vectors
  $\bfx \in \bbR^n$ such that $A\bfx = \boldsymbol{0}_m$. In other words,
  % 
  \begin{align}
    \calN(A) = \{ \bfx \in \bbR^n \mid \boldsymbol{0}_m = A\bfx \}.
  \end{align}
  % 

  The task  of finding  the column space or the   null  space is the task  of
  finding the minimal set  of  vectors  that  \textit{span}   the vector  spaces
  $\calR(A)$  or $\calN(A)$ respectively.
\end{frame}

\begin{frame}
  Find the $\calR(A)$ and $\calN(A)$ of the matrix $A$
  \[
    A   =  \begin{bmatrix}
      1 &   2  &  3  \\
      4 & 5 &   6 \\
      2 & 4 &   6
    \end{bmatrix}
    = \begin{bmatrix}  \bfr_1^\top  \\  \bfr_2^\top \\ \bfr_3^\top\end{bmatrix}
  \]
\end{frame}

\begin{frame}{Eigenvalues  and Eigenvectors}

For a  square  matrix $A$, the $\lambda_i$ and  $\bfx_i$ that satisfy  the
following equation are called eigenvalues and  eigenvectors  respectively.
\begin{align}
  A  \bfx &= \lambda \bfx \text{ or } (A  - \lambda I)\bfx  = 0
\end{align}

$\lambda$ is   chosen to ensure  that   $A  -  \lambda I$  has null space,
hence, characteristic   equation
\begin{align}
  \det(A  - \lambda I) = 0 
 \end{align}

 For  symmetrix matrix $A =  A^\top$, eigenvalues  are  real, and eigenvectors
 are orthonormal,
 \begin{align}
   &A[\bfx_1, \dots,   \bfx_n]  = [\bfx_1, \dots,   \bfx_n]\begin{bmatrix}\lambda_1 &   \dots   &  0 \\
     \vdots   &   \ddots &  \vdots \\
   0 &   \dots  &  \lambda_n \end{bmatrix}
                  \\
   &A  S = S  \Lambda
   \\
   &\text{  if   }  A =  A^\top \text{ then   }  A   = S \Lambda S^\top
   \end{align}


\end{frame}

\begin{frame}
  
  We introduce two vocabulary words to describe what we have seen.
  Let $A$ be a square matrix and $\lambda$ a scalar.
\begin{itemize}
  \item The geometric multiplicity of $\lambda$ is the dimension of the
  $\lambda$-eigenspace. In other words, $\dim \calN( (A − λI))$.
  \item The algebraic multiplicity of $\lambda$ is the number of times $(\lambda − t)$
  occurs as a factor of $\det(A − tI)$.
  \end{itemize}
  \begin{theorem}
  geometric multiplicity of $\lambda$ $\le$ algebraic multiplicity of $\lambda$
  \end{theorem}
\end{frame}

\begin{frame}{Numerical example}
  \[
  A   =  \begin{bmatrix}
    1 &   2  &  3  \\
    4 & 5 &   6 \\
    2 & 4 &   6
  \end{bmatrix}
  \]
Find eigen values and eigen vectors.
\end{frame}

\begin{frame}{Singular Value  Decomposition (SVD)}
  \begin{align}
    A  &=   U  \begin{bmatrix}\Sigma   &  0  \\   0  &  0 \end{bmatrix} V^\top \\
    A^\top A &= V \Sigma^2  V^{-1} \\
    A^\top A \bfv_i  &= \lambda_i \bfv_i & \lambda_i = \sigma_i^2\\
    A V   &= U \begin{bmatrix}\Sigma   &  0  \\   0  &  0 \end{bmatrix}\\
    U^+   &=  \Sigma^{-1}AV^+
    \end{align}
\end{frame}

\begin{frame}{Numerical example}
  Find singular value decomposition
  \[
    A   =  \begin{bmatrix}
      1 &   2  &  3  \\
      4 & 5 &   6 \\
      2 & 4 &   6
    \end{bmatrix}
  \]
\end{frame}

\begin{frame}{Homography}
  \includegraphics[width=\linewidth]{media/homography-maps-a-line-to-a-line.png}
\end{frame}
\begin{frame}{Examples  of  Homography}
  \includegraphics[width=\linewidth]{media/examples-of-homography.png}
\end{frame}

\begin{frame}
  \includegraphics[width=0.60\linewidth]{media/audi top view camera.jpg}
\end{frame}

\begin{frame}{Computing Homography}
  \includegraphics[width=0.45\linewidth]{media/removing-perspective-distortion.png}
  \includegraphics[width=0.45\linewidth]{media/removing-perspective-distortion-b.png}
\end{frame}


\begin{frame}{Computing Homography}
  \includegraphics[width=0.45\linewidth]{media/removing-perspective-distortion.png}
  \includegraphics[width=0.45\linewidth]{media/removing-perspective-distortion-b.png}
\end{frame}

\begin{frame}{Solving for Homography derivation}
\end{frame}

\begin{frame}{Direct Linear Transformation   (DLT) algorithm}
  \includegraphics[width=\linewidth]{media/DLT-algorithm.png}
\end{frame}

\begin{frame}{2D homography}
  Given a set of points $\bfx_i \in \bbP^2$ and a corresponding set of
  points $\bfx'_i \in \bbP^2$, compute the projective transformation that takes each
  $\bfx_i$ to $\bfx'_i$ . In a practical situation, the points $\bfx_i$ and   $\bfx'_i$  are points in two images
  (or the same image), each image being considered as a projective plane  $\bbP^2$.
\end{frame}

\begin{frame}{3D  to  2D camera projection matrix estimation}
  Given a set of points $\bfX_i$ in 3D space, and a set
  of corresponding points $\bfx_i$ in an image, find the 3D to 2D projective
  $\bfP$ mapping
  that maps $\bfX_i$ to $\bfx_i  =  \bfP\bfX_i$.
\end{frame}

\end{document}